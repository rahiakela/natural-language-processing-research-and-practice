{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building-chatbot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzarirHdbQlrgmU1VZuNTj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/real-world-natural-language-processing/6-sequence-to-sequence-models/building_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building a chatbot"
      ],
      "metadata": {
        "id": "l-kMJDA0mIf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I’m going to go over another application of a Seq2Seq model—a chatbot,\n",
        "which is an NLP application with which you can have a conversation. We are\n",
        "going to build a very simple yet functional chatbot using a Seq2Seq model and discuss\n",
        "techniques and challenges in building intelligent agents.\n",
        "\n",
        "To recap, two main types of\n",
        "dialogue systems exist: **task-oriented and chatbots**. \n",
        "\n",
        "Although task-oriented dialogue\n",
        "systems are used to achieve some specific goals, such as making a reservation at a\n",
        "restaurant and obtaining some information.\n",
        "\n",
        "chatbots are used to have conversations\n",
        "with humans. Conversational technologies are currently a hot topic among NLP practitioners,\n",
        "due to the success and proliferation of commercial conversational AI systems\n",
        "such as Amazon Alexa, Apple Siri, and Google Assistant.\n",
        "\n",
        "If you think of a conversation as a set of “turns” where the response is generated by\n",
        "pattern matching against the previous utterance, this starts to look a lot like a typical\n",
        "NLP problem. \n",
        "\n",
        "In particular, if you regard dialogues as a problem where an NLP system\n",
        "is simply converting your question to its response, this is exactly where we can\n",
        "apply the Seq2Seq models we covered in this chapter so far. We can treat the previous\n",
        "(human’s) utterance as a foreign sentence and have the chatbot “translate” it into\n",
        "another language. \n",
        "\n",
        "Even though these two languages are both English in this case, it is\n",
        "a common practice in NLP to treat the input and the output as two different languages\n",
        "and apply a Seq2Seq model to them, including summarization (longer text to\n",
        "a shorter one) and grammatical error correction (text with errors to one without)."
      ],
      "metadata": {
        "id": "PperjxQomJUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "5rkHq3KQmzwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tl0INaYm0lb",
        "outputId": "1e4400b1-712f-4fa7-b219-4cf40e62c81d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 39.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 35.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.0 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download and expand the dataset"
      ],
      "metadata": {
        "id": "JRkuIurWm8T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p data/chatbot\n",
        "wget https://realworldnlpbook.s3.amazonaws.com/data/chatbot/selfdialog.zip\n",
        "unzip selfdialog.zip -d data/chatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tJkcjJIm8v7",
        "outputId": "2fed96db-05e1-4e30-d92c-dc9a6e612730"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-14 11:03:28--  https://realworldnlpbook.s3.amazonaws.com/data/chatbot/selfdialog.zip\n",
            "Resolving realworldnlpbook.s3.amazonaws.com (realworldnlpbook.s3.amazonaws.com)... 52.217.168.233\n",
            "Connecting to realworldnlpbook.s3.amazonaws.com (realworldnlpbook.s3.amazonaws.com)|52.217.168.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13668021 (13M) [application/zip]\n",
            "Saving to: ‘selfdialog.zip’\n",
            "\n",
            "selfdialog.zip      100%[===================>]  13.03M  36.9MB/s    in 0.4s    \n",
            "\n",
            "2021-12-14 11:03:29 (36.9 MB/s) - ‘selfdialog.zip’ saved [13668021/13668021]\n",
            "\n",
            "Archive:  selfdialog.zip\n",
            "  inflating: data/chatbot/selfdialog.valid.tok.en  \n",
            "  inflating: data/chatbot/selfdialog.valid.tok.fr  \n",
            "  inflating: data/chatbot/selfdialog.train.tok.en  \n",
            "  inflating: data/chatbot/selfdialog.train.tok.fr  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing a dataset"
      ],
      "metadata": {
        "id": "hA8hI1MLnLDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case study, we are going to use [The Self-dialogue Corpus](https://github.com/jfainberg/self_dialogue_corpus), a collection of 24,165 conversations. What’s special\n",
        "about this dataset is that these conversations are not actual ones between two people,\n",
        "but fictitious ones written by one person who plays both sides.\n",
        "\n",
        "By collecting made-up conversations instead, the Self-dialogue\n",
        "Corpus improves the quality for half the original cost (because you need only one person\n",
        "versus two people!).\n",
        "\n",
        "You can use the following combination of the paste command (to stitch files horizontally)\n",
        "and the head command to peek at the beginning of the training portion."
      ],
      "metadata": {
        "id": "c8zAa3dLnLt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!paste data/chatbot/selfdialog.train.tok.fr data/chatbot/selfdialog.train.tok.en | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4kNyU_wnjP5",
        "outputId": "e651c71e-d2ca-4a72-aa51-edd5aa13cd72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I 'm playing basketball this weekend , do you want to come along ?\tNo thanks , I rented several movies I want to stay home and watch .\n",
            "Have you played in a band ?\tWhat type of band ?\n",
            "What type of band ?\tA rock and roll band .\n",
            "A rock and roll band .\tSure , I played in one for years .\n",
            "Sure , I played in one for years .\tNo kidding ?\n",
            "No kidding ?\tI played in rock love love .\n",
            "I played in rock love love .\tYou played local ?\n",
            "You played local ?\tYes\n",
            "Yes\tWould you play again ?\n",
            "Would you play again ?\tWhy ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, each line consists of an utterance (on the left) and a response to it (on the right).\n",
        "\n",
        "Notice that this dataset has the same structure as the Spanish-English parallel\n",
        "corpus. \n",
        "\n",
        "The next step is to run the fairseq-preprocess\n",
        "command to convert it to a binary format as follows:"
      ],
      "metadata": {
        "id": "U2orrC8qn-2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess \\\n",
        "  --source-lang fr \\\n",
        "  --target-lang en \\\n",
        "  --trainpref data/chatbot/selfdialog.train.tok \\\n",
        "  --validpref data/chatbot/selfdialog.valid.tok \\\n",
        "  --destdir data/chatbot-bin \\\n",
        "  --thresholdsrc 3 \\\n",
        "  --thresholdtgt 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_JIw_FKoG-D",
        "outputId": "930cca3d-3262-4371-bba5-b8e325ed4697"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-14 11:09:33 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data/chatbot-bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='fr', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=3, thresholdtgt=3, tokenizer=None, tpu=False, trainpref='data/chatbot/selfdialog.train.tok', user_dir=None, validpref='data/chatbot/selfdialog.valid.tok', workers=1)\n",
            "2021-12-14 11:09:52 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 22072 types\n",
            "2021-12-14 11:10:17 | INFO | fairseq_cli.preprocess | [fr] data/chatbot/selfdialog.train.tok.fr: 313882 sents, 3969558 tokens, 1.02% replaced by <unk>\n",
            "2021-12-14 11:10:17 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 22072 types\n",
            "2021-12-14 11:10:20 | INFO | fairseq_cli.preprocess | [fr] data/chatbot/selfdialog.valid.tok.fr: 34673 sents, 444225 tokens, 1.34% replaced by <unk>\n",
            "2021-12-14 11:10:20 | INFO | fairseq_cli.preprocess | [en] Dictionary: 22192 types\n",
            "2021-12-14 11:10:44 | INFO | fairseq_cli.preprocess | [en] data/chatbot/selfdialog.train.tok.en: 313882 sents, 4006556 tokens, 1.02% replaced by <unk>\n",
            "2021-12-14 11:10:44 | INFO | fairseq_cli.preprocess | [en] Dictionary: 22192 types\n",
            "2021-12-14 11:10:47 | INFO | fairseq_cli.preprocess | [en] data/chatbot/selfdialog.valid.tok.en: 34673 sents, 448375 tokens, 1.32% replaced by <unk>\n",
            "2021-12-14 11:10:47 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/chatbot-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, this is similar to what we ran for the Spanish translator example. \n",
        "\n",
        "Just pay attention\n",
        "to what you specify as the source language—we are using fr instead of es here."
      ],
      "metadata": {
        "id": "etBbBjqLok5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and running a chatbot"
      ],
      "metadata": {
        "id": "SfhiO_7zoliG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_W8bfP0kov66"
      }
    }
  ]
}