{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building-chatbot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNM5ivNITDku8f2TWb0ZbVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/real-world-natural-language-processing/6-sequence-to-sequence-models/building_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building a chatbot"
      ],
      "metadata": {
        "id": "l-kMJDA0mIf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I’m going to go over another application of a Seq2Seq model—a chatbot,\n",
        "which is an NLP application with which you can have a conversation. We are\n",
        "going to build a very simple yet functional chatbot using a Seq2Seq model and discuss\n",
        "techniques and challenges in building intelligent agents.\n",
        "\n",
        "To recap, two main types of\n",
        "dialogue systems exist: **task-oriented and chatbots**. \n",
        "\n",
        "Although task-oriented dialogue\n",
        "systems are used to achieve some specific goals, such as making a reservation at a\n",
        "restaurant and obtaining some information.\n",
        "\n",
        "chatbots are used to have conversations\n",
        "with humans. Conversational technologies are currently a hot topic among NLP practitioners,\n",
        "due to the success and proliferation of commercial conversational AI systems\n",
        "such as Amazon Alexa, Apple Siri, and Google Assistant.\n",
        "\n",
        "If you think of a conversation as a set of “turns” where the response is generated by\n",
        "pattern matching against the previous utterance, this starts to look a lot like a typical\n",
        "NLP problem. \n",
        "\n",
        "In particular, if you regard dialogues as a problem where an NLP system\n",
        "is simply converting your question to its response, this is exactly where we can\n",
        "apply the Seq2Seq models we covered in this chapter so far. We can treat the previous\n",
        "(human’s) utterance as a foreign sentence and have the chatbot “translate” it into\n",
        "another language. \n",
        "\n",
        "Even though these two languages are both English in this case, it is\n",
        "a common practice in NLP to treat the input and the output as two different languages\n",
        "and apply a Seq2Seq model to them, including summarization (longer text to\n",
        "a shorter one) and grammatical error correction (text with errors to one without)."
      ],
      "metadata": {
        "id": "PperjxQomJUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "5rkHq3KQmzwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tl0INaYm0lb",
        "outputId": "c8520fac-01bf-452e-cc05-c3f349363519"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 225 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 235 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 276 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 307 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 337 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 348 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 358 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 368 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 378 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 389 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 399 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 409 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 419 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 430 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 440 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 450 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 460 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 471 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 481 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 491 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 501 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 512 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 522 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 542 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 552 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 563 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 573 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 593 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 604 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 614 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 624 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 634 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 645 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 655 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 665 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 675 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 686 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 696 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 706 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 716 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 727 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 737 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 747 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 757 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 768 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 778 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 788 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 798 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 808 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 819 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 829 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 839 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 849 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 860 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 870 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 880 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 890 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 901 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 911 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 921 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 931 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 942 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 952 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 962 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 972 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 983 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 993 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.0 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.0 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.4 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.6 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 13.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 13.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 50.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 54.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 34.2 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download and expand the dataset"
      ],
      "metadata": {
        "id": "JRkuIurWm8T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p data/chatbot\n",
        "wget https://realworldnlpbook.s3.amazonaws.com/data/chatbot/selfdialog.zip\n",
        "unzip selfdialog.zip -d data/chatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tJkcjJIm8v7",
        "outputId": "8dcbdb71-0f62-40ab-b9e4-f3e0a97c0101"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-16 10:00:35--  https://realworldnlpbook.s3.amazonaws.com/data/chatbot/selfdialog.zip\n",
            "Resolving realworldnlpbook.s3.amazonaws.com (realworldnlpbook.s3.amazonaws.com)... 52.216.200.211\n",
            "Connecting to realworldnlpbook.s3.amazonaws.com (realworldnlpbook.s3.amazonaws.com)|52.216.200.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13668021 (13M) [application/zip]\n",
            "Saving to: ‘selfdialog.zip’\n",
            "\n",
            "selfdialog.zip      100%[===================>]  13.03M  13.2MB/s    in 1.0s    \n",
            "\n",
            "2021-12-16 10:00:36 (13.2 MB/s) - ‘selfdialog.zip’ saved [13668021/13668021]\n",
            "\n",
            "Archive:  selfdialog.zip\n",
            "  inflating: data/chatbot/selfdialog.valid.tok.en  \n",
            "  inflating: data/chatbot/selfdialog.valid.tok.fr  \n",
            "  inflating: data/chatbot/selfdialog.train.tok.en  \n",
            "  inflating: data/chatbot/selfdialog.train.tok.fr  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing a dataset"
      ],
      "metadata": {
        "id": "hA8hI1MLnLDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case study, we are going to use [The Self-dialogue Corpus](https://github.com/jfainberg/self_dialogue_corpus), a collection of 24,165 conversations. What’s special\n",
        "about this dataset is that these conversations are not actual ones between two people,\n",
        "but fictitious ones written by one person who plays both sides.\n",
        "\n",
        "By collecting made-up conversations instead, the Self-dialogue\n",
        "Corpus improves the quality for half the original cost (because you need only one person\n",
        "versus two people!).\n",
        "\n",
        "You can use the following combination of the paste command (to stitch files horizontally)\n",
        "and the head command to peek at the beginning of the training portion."
      ],
      "metadata": {
        "id": "c8zAa3dLnLt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!paste data/chatbot/selfdialog.train.tok.fr data/chatbot/selfdialog.train.tok.en | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4kNyU_wnjP5",
        "outputId": "c8b34778-2f67-40cb-981b-54ad12e2c7e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I 'm playing basketball this weekend , do you want to come along ?\tNo thanks , I rented several movies I want to stay home and watch .\n",
            "Have you played in a band ?\tWhat type of band ?\n",
            "What type of band ?\tA rock and roll band .\n",
            "A rock and roll band .\tSure , I played in one for years .\n",
            "Sure , I played in one for years .\tNo kidding ?\n",
            "No kidding ?\tI played in rock love love .\n",
            "I played in rock love love .\tYou played local ?\n",
            "You played local ?\tYes\n",
            "Yes\tWould you play again ?\n",
            "Would you play again ?\tWhy ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, each line consists of an utterance (on the left) and a response to it (on the right).\n",
        "\n",
        "Notice that this dataset has the same structure as the Spanish-English parallel\n",
        "corpus. \n",
        "\n",
        "The next step is to run the fairseq-preprocess\n",
        "command to convert it to a binary format as follows:"
      ],
      "metadata": {
        "id": "U2orrC8qn-2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess \\\n",
        "  --source-lang fr \\\n",
        "  --target-lang en \\\n",
        "  --trainpref data/chatbot/selfdialog.train.tok \\\n",
        "  --validpref data/chatbot/selfdialog.valid.tok \\\n",
        "  --destdir data/chatbot-bin \\\n",
        "  --thresholdsrc 3 \\\n",
        "  --thresholdtgt 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_JIw_FKoG-D",
        "outputId": "4156f72c-912d-4042-9070-e37fc088c268"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-16 10:00:44 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data/chatbot-bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='fr', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=3, thresholdtgt=3, tokenizer=None, tpu=False, trainpref='data/chatbot/selfdialog.train.tok', user_dir=None, validpref='data/chatbot/selfdialog.valid.tok', workers=1)\n",
            "2021-12-16 10:01:04 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 22072 types\n",
            "2021-12-16 10:01:30 | INFO | fairseq_cli.preprocess | [fr] data/chatbot/selfdialog.train.tok.fr: 313882 sents, 3969558 tokens, 1.02% replaced by <unk>\n",
            "2021-12-16 10:01:30 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 22072 types\n",
            "2021-12-16 10:01:33 | INFO | fairseq_cli.preprocess | [fr] data/chatbot/selfdialog.valid.tok.fr: 34673 sents, 444225 tokens, 1.34% replaced by <unk>\n",
            "2021-12-16 10:01:33 | INFO | fairseq_cli.preprocess | [en] Dictionary: 22192 types\n",
            "2021-12-16 10:01:59 | INFO | fairseq_cli.preprocess | [en] data/chatbot/selfdialog.train.tok.en: 313882 sents, 4006556 tokens, 1.02% replaced by <unk>\n",
            "2021-12-16 10:01:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 22192 types\n",
            "2021-12-16 10:02:02 | INFO | fairseq_cli.preprocess | [en] data/chatbot/selfdialog.valid.tok.en: 34673 sents, 448375 tokens, 1.32% replaced by <unk>\n",
            "2021-12-16 10:02:02 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/chatbot-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, this is similar to what we ran for the Spanish translator example. \n",
        "\n",
        "Just pay attention\n",
        "to what you specify as the source language—we are using fr instead of es here."
      ],
      "metadata": {
        "id": "etBbBjqLok5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and running a chatbot"
      ],
      "metadata": {
        "id": "SfhiO_7zoliG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the training data for the chatbot is ready, let’s train a Seq2Seq model from\n",
        "this data. \n",
        "\n",
        "You can invoke the fairseq-train command with almost identical parameters\n",
        "to the last time, as shown next:"
      ],
      "metadata": {
        "id": "_W8bfP0kov66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-train \\\n",
        "  data/chatbot-bin \\\n",
        "  --arch lstm \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --optimizer adam \\\n",
        "  --lr 1.0e-3 \\\n",
        "  --max-tokens 4096 \\\n",
        "  --save-dir data/chatbot-ckpt"
      ],
      "metadata": {
        "id": "rT0p3c-5sFna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As previously, pay attention to how the validation loss changes every epoch. When I\n",
        "tried this, the validation loss decreased for about five epochs but then started to slowly\n",
        "creep back up. \n",
        "\n",
        "Feel free to stop the training command by pressing `Ctrl + C` after you observe the validation loss leveling out. Fairseq will automatically save the best model\n",
        "(measured by the validation loss) to `checkpoint_best.pt`.\n",
        "\n",
        "Finally, you can run the chatbot model by invoking the fairseq-interactive\n",
        "command, as shown here:"
      ],
      "metadata": {
        "id": "TxrcMB74sqjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive data/chatbot-bin \\\n",
        "  --path data/chatbot-ckpt/checkpoint_best.pt \\\n",
        "  --beam 5 \\\n",
        "  --source-lang fr \\\n",
        "  --target-lang en"
      ],
      "metadata": {
        "id": "hzTBD21Ds2CH",
        "outputId": "b1fc51cb-04b4-414f-c999-5d6b97302ad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-16 11:16:42 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data/chatbot-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='data/chatbot-ckpt/checkpoint_best.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='fr', target_lang='en', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-12-16 11:16:42 | INFO | fairseq.tasks.translation | [fr] dictionary: 22072 types\n",
            "2021-12-16 11:16:42 | INFO | fairseq.tasks.translation | [en] dictionary: 22192 types\n",
            "2021-12-16 11:16:42 | INFO | fairseq_cli.interactive | loading model(s) from data/chatbot-ckpt/checkpoint_best.pt\n",
            "2021-12-16 11:16:46 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-12-16 11:16:46 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "Hi\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n",
            "S-0\tHi\n",
            "W-0\t0.108\tseconds\n",
            "H-0\t-1.1915801763534546\tHey there .\n",
            "D-0\t-1.1915801763534546\tHey there .\n",
            "P-0\t-0.4067 -1.9866 -2.2050 -0.1679\n",
            "How are you ?\n",
            "S-1\tHow are you ?\n",
            "W-1\t0.070\tseconds\n",
            "H-1\t-1.456044316291809\tDoing good .\n",
            "D-1\t-1.456044316291809\tDoing good .\n",
            "P-1\t-2.5470 -0.9388 -1.4152 -0.9232\n",
            "Good.\n",
            "S-2\t<unk>\n",
            "W-2\t0.038\tseconds\n",
            "H-2\t-1.9213122129440308\tWho is that ?\n",
            "D-2\t-1.9213122129440308\tWho is that ?\n",
            "P-2\t-5.0441 -1.2893 -2.6971 -0.5355 -0.0405\n",
            "Do you have a favorite team ?\n",
            "S-3\tDo you have a favorite team ?\n",
            "W-3\t0.047\tseconds\n",
            "H-3\t-1.4477550983428955\tI like the Patriots .\n",
            "D-3\t-1.4477550983428955\tI like the Patriots .\n",
            "P-3\t-1.2806 -1.7637 -0.4171 -4.3084 -0.7411 -0.1755\n",
            "Do you have a favorite team ?\n",
            "S-4\tDo you have a favorite team ?\n",
            "W-4\t0.041\tseconds\n",
            "H-4\t-1.4477550983428955\tI like the Patriots .\n",
            "D-4\t-1.4477550983428955\tI like the Patriots .\n",
            "P-4\t-1.2806 -1.7637 -0.4171 -4.3084 -0.7411 -0.1755\n",
            "How about you ?\n",
            "S-5\tHow about you ?\n",
            "W-5\t0.075\tseconds\n",
            "H-5\t-1.7204129695892334\tI 'm a huge fan of the first one .\n",
            "D-5\t-1.7204129695892334\tI 'm a huge fan of the first one .\n",
            "P-5\t-0.8986 -3.4258 -1.9566 -2.0459 -0.3997 -0.2651 -1.7197 -4.5694 -2.0192 -1.1067 -0.5179\n",
            "What 's your favorite movie ?\n",
            "S-6\tWhat 's your favorite movie ?\n",
            "W-6\t0.068\tseconds\n",
            "H-6\t-1.245644211769104\tI would have to say Forrest Gump .\n",
            "D-6\t-1.245644211769104\tI would have to say Forrest Gump .\n",
            "P-6\t-2.0755 -3.1754 -0.5249 -0.0265 -0.1715 -4.6601 -0.0141 -0.2890 -0.2737\n",
            "Oh yeah , I like that movie too .\n",
            "S-7\tOh yeah , I like that movie too .\n",
            "W-7\t0.060\tseconds\n",
            "H-7\t-1.6127358675003052\tYeah , it 's a great movie .\n",
            "D-7\t-1.6127358675003052\tYeah , it 's a great movie .\n",
            "P-7\t-3.4893 -0.2937 -2.0116 -1.1586 -2.0817 -2.5635 -0.9841 -1.2116 -0.7204\n",
            "What 's your name ?\n",
            "S-8\tWhat 's your name ?\n",
            "W-8\t0.115\tseconds\n",
            "H-8\t-1.4420264959335327\tI do n't know .\n",
            "D-8\t-1.4420264959335327\tI do n't know .\n",
            "P-8\t-2.1971 -3.3039 -0.0547 -0.6152 -0.8170 -1.6643\n",
            "What do you do ?\n",
            "S-9\tWhat do you do ?\n",
            "W-9\t0.123\tseconds\n",
            "H-9\t-1.5443986654281616\tI do n't know , but I do n't think I 've ever heard of it .\n",
            "D-9\t-1.5443986654281616\tI do n't know , but I do n't think I 've ever heard of it .\n",
            "P-9\t-1.2573 -2.6788 -0.6943 -1.2878 -2.8194 -1.4236 -0.7287 -2.3877 -0.6542 -2.8365 -2.0419 -2.3339 -1.3522 -1.6575 -0.5705 -2.2059 -0.5122 -0.3567\n",
            "Are you a student ?\n",
            "S-10\tAre you a student ?\n",
            "W-10\t0.042\tseconds\n",
            "H-10\t-1.2159966230392456\tNot at all .\n",
            "D-10\t-1.2159966230392456\tNot at all .\n",
            "P-10\t-2.3661 -2.1794 -0.1347 -0.5392 -0.8606\n",
            "What 's your favorite show ?\n",
            "S-11\tWhat 's your favorite show ?\n",
            "W-11\t0.149\tseconds\n",
            "H-11\t-1.4904688596725464\tI 'd have to say that my favorite would have to be the Beatles .\n",
            "D-11\t-1.4904688596725464\tI 'd have to say that my favorite would have to be the Beatles .\n",
            "P-11\t-1.4840 -2.8190 -0.8573 -0.0152 -0.1979 -3.5424 -2.7026 -0.5703 -2.9971 -0.9760 -0.1300 -0.0340 -3.3594 -3.5241 -0.3747 -0.2636\n",
            "then get lost.\n",
            "S-12\tthen get <unk>\n",
            "W-12\t0.068\tseconds\n",
            "H-12\t-2.10901141166687\ti do n't think it 's a good thing\n",
            "D-12\t-2.10901141166687\ti do n't think it 's a good thing\n",
            "P-12\t-3.0217 -3.7719 -0.7101 -1.7574 -2.9387 -1.2520 -2.4465 -3.0576 -1.6094 -0.5248\n",
            "You are stupid boy?\n",
            "S-13\tYou are stupid <unk>\n",
            "W-13\t0.028\tseconds\n",
            "H-13\t-2.1614904403686523\tI dont know\n",
            "D-13\t-2.1614904403686523\tI dont know\n",
            "P-13\t-3.0083 -3.5264 -0.8720 -1.2392\n",
            "Then what do you know?\n",
            "S-14\tThen what do you <unk>\n",
            "W-14\t0.063\tseconds\n",
            "H-14\t-1.794487714767456\tI am a huge fan of the <unk>\n",
            "D-14\t-1.794487714767456\tI am a huge fan of the <unk>\n",
            "P-14\t-1.3607 -2.7823 -2.7193 -2.0958 -0.4280 -0.1675 -1.6151 -3.6880 -1.2936\n",
            "exit\n",
            "S-15\t<unk>\n",
            "W-15\t0.035\tseconds\n",
            "H-15\t-1.9213122129440308\tWho is that ?\n",
            "D-15\t-1.9213122129440308\tWho is that ?\n",
            "P-15\t-5.0441 -1.2893 -2.6971 -0.5355 -0.0405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can type your source sentences and have a conversion\n",
        "with your chatbot by having them “translate” to another language! Here’s part of\n",
        "a conversation that I had with the model that I trained (I added boldface for clarity).\n",
        "\n",
        "In this example, the conversation looks natural. Because the Self-dialogue Corpus is\n",
        "built by restricting the set of possible conversation topics, the conversation is more\n",
        "likely to go smoothly if you stay on such topics (movie, sports, music, and so on).\n",
        "\n",
        "However, as soon as you start talking about unfamiliar topics, the chatbot loses its\n",
        "confidence in its answers.\n",
        "\n",
        "This is a well-known phenomenon—a simple Seq2Seq-based chatbot quickly regresses\n",
        "to producing cookie-cutter answers such as “I don’t know” and “I’m not sure” whenever\n",
        "asked about something it’s not familiar with. This has to do with the way we\n",
        "trained this chatbot. Because we trained the model so that it minimizes the loss in the\n",
        "training data, the best strategy it can take to reduce the loss is to produce something\n",
        "applicable to as many input sentences as possible. Very generic phrases such as “I\n",
        "don’t know” can be an answer for many questions, so it’s a great way to play it safe and\n",
        "reduce the loss!"
      ],
      "metadata": {
        "id": "_SlUFi1stZHO"
      }
    }
  ]
}