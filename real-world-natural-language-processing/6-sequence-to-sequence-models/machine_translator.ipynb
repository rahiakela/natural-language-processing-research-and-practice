{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-translator.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOwg6ALSl/wuTD5YAbD7eG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/real-world-natural-language-processing/6-sequence-to-sequence-models/machine_translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKJ5NY0ZJiPD"
      },
      "source": [
        "##Machine Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3nTcGA3Jkzy"
      },
      "source": [
        "In this notebook, we are going to build a working MT system. Instead of writing any\n",
        "Python code to do that, weâ€™ll make the most of existing MT frameworks. A number of\n",
        "open source frameworks make it easier to build MT systems, including [Moses](http://www.statmt.org/moses/) for SMT and [OpenNMT](http://opennmt.net/) for NMT.\n",
        "\n",
        "But, we will use [Fairseq](https://github.com/pytorch/fairseq), an NMT\n",
        "toolkit developed by Facebook that is becoming more and more popular among NLP\n",
        "practitioners these days.\n",
        "\n",
        "The following aspects make Fairseq a good choice for developing\n",
        "an NMT system quickly:\n",
        "\n",
        "- it is a modern framework that comes with a number\n",
        "of predefined state-of-the-art NMT models that you can use out of the box;\n",
        "- it is very extensible, meaning you can quickly implement your own model by following their API;\n",
        "- it is very fast, supporting multi-GPU and distributed training by default.\n",
        "\n",
        "Thanks to its powerful models, you can build a decent quality NMT system within a couple of hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OypcEydKKfC2"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLVwz4BMKgHT"
      },
      "source": [
        "!pip -q install fairseq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO2ncsqWKu3k"
      },
      "source": [
        "Let's download and expand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ee7uVfRKxU2"
      },
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p data/mt\n",
        "wget https://realworldnlpbook.s3.amazonaws.com/data/mt/tatoeba.eng_spa.zip\n",
        "unzip tatoeba.eng_spa.zip -d data/mt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGqZISQeLc-A"
      },
      "source": [
        "The\n",
        "corpus consists of approximately 200,000 English sentences and their Spanish translations.\n",
        "I went ahead and already formatted the dataset so that you can use it without worrying about obtaining the data, tokenizing the text, and so on. The dataset is\n",
        "already split into train, validate, and test subsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "788vSarZLf0U"
      },
      "source": [
        "##Preparing the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qah-tp9yLibl"
      },
      "source": [
        ""
      ]
    }
  ]
}