{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-dense-vectors.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8qhNq72k7/gWqk+G/GtNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/nlp-for-semantic-search/1_dense_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dense Vectors"
      ],
      "metadata": {
        "id": "4MV-BEYafocT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://www.pinecone.io/learn/dense-vector-embeddings-nlp/\n",
        "\n",
        "https://www.youtube.com/watch?v=bVZJ_O_-0RE"
      ],
      "metadata": {
        "id": "5X7d4RahfrM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "41Q0OtgioA40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers\n",
        "!pip -q install sentence-transformers"
      ],
      "metadata": {
        "id": "_45ApvtOeFwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "F0uyB4hmeM-_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentence Similarity"
      ],
      "metadata": {
        "id": "0F2oQHhdovkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s look at how we can quickly pull together some sentence embeddings using the sentence-transformers library."
      ],
      "metadata": {
        "id": "8OGzYsLhpbQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "daacuqrMeN4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can go ahead and encode a few sentences, some more similar than others — while sharing very few matching words."
      ],
      "metadata": {
        "id": "j1iWumDbpeyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "   \"it caught him off guard that space smelled of seared steak\",\n",
        "    \"she could not decide between painting her teeth or brushing her nails\",\n",
        "    \"he thought there'd be sufficient time is he hid his watch\",\n",
        "    \"the bees decided to have a mutiny against their queen\",\n",
        "    \"the sign said there was road work ahead so she decided to speed up\",\n",
        "    \"on a scale of one to ten, what's your favorite flavor of color?\",\n",
        "    \"flying stinging insects rebelled in opposition to the matriarch\"          \n",
        "]"
      ],
      "metadata": {
        "id": "HtGLcDZHea2m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(sentences)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96UrOZq3eeer",
        "outputId": "a889348a-5658-49f9-865d-e91d32eecc56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl_2LLiIeogq",
        "outputId": "008ef30d-b53f-43b9-b7e8-df8e6571cd38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.07613575,  0.03554152, -0.04853423, ...,  0.02156135,\n",
              "        -0.02294155, -0.01750991],\n",
              "       [ 0.02348459,  0.03777696, -0.0244106 , ..., -0.00101797,\n",
              "         0.01494204, -0.00690051],\n",
              "       [-0.01087208, -0.06204989, -0.02355074, ...,  0.04565978,\n",
              "         0.00899556, -0.04353992],\n",
              "       ...,\n",
              "       [-0.00952114, -0.00817684, -0.0054946 , ..., -0.01066917,\n",
              "         0.00550096, -0.01924828],\n",
              "       [-0.00313652,  0.03131971, -0.00896536, ...,  0.04947064,\n",
              "        -0.04866311, -0.00352198],\n",
              "       [ 0.0035543 , -0.04229828,  0.01761915, ...,  0.01523382,\n",
              "         0.01262348, -0.01886442]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.util import cos_sim"
      ],
      "metadata": {
        "id": "ySgTVj-weqE3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOGd23SfgE1I",
        "outputId": "800ea6da-de4c-400e-b885-84bb31294c18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it caught him off guard that space smelled of seared steak',\n",
              " 'she could not decide between painting her teeth or brushing her nails',\n",
              " \"he thought there'd be sufficient time is he hid his watch\",\n",
              " 'the bees decided to have a mutiny against their queen',\n",
              " 'the sign said there was road work ahead so she decided to speed up',\n",
              " \"on a scale of one to ten, what's your favorite flavor of color?\",\n",
              " 'flying stinging insects rebelled in opposition to the matriarch']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[-1] # get last elemenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wL0PoAzLgHSL",
        "outputId": "7874a67b-7a3d-476a-a6f2-0cdc1038423a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'flying stinging insects rebelled in opposition to the matriarch'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:-1] # get all except last elemenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMD15ZaYgI-a",
        "outputId": "5b76684b-e6fe-41fc-82ee-fba2bbd9f170"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it caught him off guard that space smelled of seared steak',\n",
              " 'she could not decide between painting her teeth or brushing her nails',\n",
              " \"he thought there'd be sufficient time is he hid his watch\",\n",
              " 'the bees decided to have a mutiny against their queen',\n",
              " 'the sign said there was road work ahead so she decided to speed up',\n",
              " \"on a scale of one to ten, what's your favorite flavor of color?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And what does our sentence transformer produce from these sentences? A 768-dimensional dense representation of our sentence. The performance of these embeddings when compared using a similarity metric such as cosine similarity is, in most cases — excellent."
      ],
      "metadata": {
        "id": "LZjpV1ZTpovI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get cosine of all elemenets with last element\n",
        "scores = cos_sim(embeddings[-1], embeddings[:-1])\n",
        "\n",
        "print(sentences[-1])\n",
        "for i, score in enumerate(scores[0]):\n",
        "  print(f\"{round(score.item(), 4)} | {sentences[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc30plKewti",
        "outputId": "4b926ba2-de2b-41bb-bc06-2c951dc07677"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flying stinging insects rebelled in opposition to the matriarch\n",
            "0.1232 | it caught him off guard that space smelled of seared steak\n",
            "0.1967 | she could not decide between painting her teeth or brushing her nails\n",
            "0.0523 | he thought there'd be sufficient time is he hid his watch\n",
            "0.6084 | the bees decided to have a mutiny against their queen\n",
            "0.1011 | the sign said there was road work ahead so she decided to speed up\n",
            "-0.0492 | on a scale of one to ten, what's your favorite flavor of color?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite our most semantically similar sentences about bees and their queen sharing zero descriptive words, our model correctly embeds these sentences in the closest vector space when measured with cosine similarity!"
      ],
      "metadata": {
        "id": "KLtImLT2ptBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question-Answering"
      ],
      "metadata": {
        "id": "F7H_ZUgAkZQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we initialize tokenizers and models for both our context (ctx) model and question model."
      ],
      "metadata": {
        "id": "I8fN9QdkljZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ctx_model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
      ],
      "metadata": {
        "id": "iii-jGyXkake"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")"
      ],
      "metadata": {
        "id": "Y9M9pKVrlHEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a question and several contexts we tokenize and encode like so:"
      ],
      "metadata": {
        "id": "pI0Zjx7FloWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "  \"what is the capital city of australia?\",\n",
        "  \"what is the best selling sci-fi book?\",\n",
        "  \"how many searches are performed on Google?\"          \n",
        "]\n",
        "contexts = [\n",
        "  \"canberra is the capital city of australia\",\n",
        "  \"what is the capital city of australia?\",\n",
        "  \"the capital city of france is paris\",\n",
        "  \"what is the best selling sci-fi book?\",\n",
        "  \"sc-fi is a popular book genre read by millions\",\n",
        "  \"the best-selling sci-fi book is dune\",\n",
        "  \"how many searches are performed on Google?\",\n",
        "  \"Google serves more than 2 trillion queries annually\",\n",
        "  \"Google is a popular search engine\"\n",
        "]"
      ],
      "metadata": {
        "id": "4SGRbCbGlo0g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb_tokens = ctx_tokenizer(contexts, max_length=256, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "xb = ctx_model(**xb_tokens)"
      ],
      "metadata": {
        "id": "r846Dl6TmBxf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xq_tokens = question_tokenizer(questions, max_length=256, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "xq = question_model(**xq_tokens)"
      ],
      "metadata": {
        "id": "JbXXHupBmeo7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.pooler_output.shape, xq.pooler_output.shape"
      ],
      "metadata": {
        "id": "WDR44UmumwB2",
        "outputId": "1f20d94c-67f2-4b52-ca53-276bde10840a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([9, 768]), torch.Size([3, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can compare our query embeddings xq against all of our context embeddings xb to see which are the most similar with cosine similarity."
      ],
      "metadata": {
        "id": "_nyEjPw-n7SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, xq_vec in enumerate(xq.pooler_output):\n",
        "  probs = cos_sim(xq_vec, xb.pooler_output)\n",
        "  argmax = torch.argmax(probs)\n",
        "  print(questions[i])\n",
        "  print(contexts[argmax])\n",
        "  print(\"---\")"
      ],
      "metadata": {
        "id": "Iy_Wxsj6n75Y",
        "outputId": "3047dbfe-6314-4771-937e-ca4463fba22b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the capital city of australia?\n",
            "canberra is the capital city of australia\n",
            "---\n",
            "what is the best selling sci-fi book?\n",
            "the best-selling sci-fi book is dune\n",
            "---\n",
            "how many searches are performed on Google?\n",
            "how many searches are performed on Google?\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of our three questions, we returned two correct answers as the very top answer. It’s clear that DPR is not the perfect model, particularly when considering the simple nature of our questions and small dataset for DPR to retrieve from."
      ],
      "metadata": {
        "id": "vhoRcKRRpAkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vision Transformers"
      ],
      "metadata": {
        "id": "ubgmtROgpLDx"
      }
    }
  ]
}