{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-building-chatbot-using-sequence-to-sequence-networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjo69+R2EE32FN+qO/B+s4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-in-action/blob/master/10-sequence-to-sequence-models-and-attention/1_building_chatbot_using_sequence_to_sequence_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJyz9isfCjnv"
      },
      "source": [
        "## Building a chatbot using sequence-to-sequence networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGaQtavyCzFt"
      },
      "source": [
        "We guide you through how to apply the various steps to train a chatbot. For the chatbot training, you’ll use the [Cornell movie dialog corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). You’ll train a sequenceto- sequence network to “adequately” reply to your questions or statements. Our chatbot example is an adopted sequence-to-sequence example from the [Keras blog](https://github.com/fchollet/keras/blob/master/examples/lstm_seq2seq.py).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5-PMsuYDLAD"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD2k3lc3DMXW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import backend as keras_backend\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import re\n",
        "import tqdm\n",
        "\n",
        "import glob\n",
        "from random import shuffle\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b71j-jnQ-xQf"
      },
      "source": [
        "!wget -q https://github.com/rahiakela/natural-language-processing-in-action/raw/master/10-sequence-to-sequence-models-and-attention/dataset/moviedialog.csv"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yMpxgBD566rR",
        "outputId": "9ef657ae-1eea-4427-db6e-64e183037859"
      },
      "source": [
        "df = pd.read_csv(\"moviedialog.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>statement</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>you're asking me out. that's so cute. what's y...</td>\n",
              "      <td>forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>no, no, it's my fault we didn't have a proper ...</td>\n",
              "      <td>cameron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>gosh, if only we could find kat a boyfriend...</td>\n",
              "      <td>let me see what i can do.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>c'esc ma tete. this is my head</td>\n",
              "      <td>right. see? you're ready for the quiz.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>how is our little find the wench a date plan p...</td>\n",
              "      <td>well, there's someone i think might be</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                    reply\n",
              "0           0  ...                               forget it.\n",
              "1           1  ...                                 cameron.\n",
              "2           2  ...                let me see what i can do.\n",
              "3           3  ...   right. see? you're ready for the quiz.\n",
              "4           4  ...  well, there's someone i think might be \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9AKl0hO_GRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "4d2dcc21-fcbb-42ec-eced-c4e45b1178eb"
      },
      "source": [
        "print(df.shape)\n",
        "df = df[[\"statement\", \"reply\"]]\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64350, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you're asking me out. that's so cute. what's y...</td>\n",
              "      <td>forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no, no, it's my fault we didn't have a proper ...</td>\n",
              "      <td>cameron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gosh, if only we could find kat a boyfriend...</td>\n",
              "      <td>let me see what i can do.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c'esc ma tete. this is my head</td>\n",
              "      <td>right. see? you're ready for the quiz.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how is our little find the wench a date plan p...</td>\n",
              "      <td>well, there's someone i think might be</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement                                    reply\n",
              "0  you're asking me out. that's so cute. what's y...                               forget it.\n",
              "1  no, no, it's my fault we didn't have a proper ...                                 cameron.\n",
              "2     gosh, if only we could find kat a boyfriend...                let me see what i can do.\n",
              "3                     c'esc ma tete. this is my head   right. see? you're ready for the quiz.\n",
              "4  how is our little find the wench a date plan p...  well, there's someone i think might be "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS5E8OXi_Jpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ea18f3-66ac-4888-86d6-3012fc356855"
      },
      "source": [
        "df = df.dropna()\n",
        "print(df.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64350, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu5OFH6YDNME"
      },
      "source": [
        "## Preparing the corpus for your training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSvyn0o_DRGf"
      },
      "source": [
        "First, you need to load the corpus and generate the training sets from it. The training data will determine the set of characters the encoder and decoder will support during the training and during the generation phase. Please note that this implementation doesn’t support characters that haven’t been included during the training phase.\n",
        "\n",
        "Using the entire Cornell Movie Dialog dataset can be computationally intensive because a few sequences have more than 2,000 tokens—2,000 time steps will take a while to unroll. But the majority of dialog samples are based on less than 100 characters.\n",
        "\n",
        "For this example, you’ve preprocessed the dialog corpus by limiting samples to those with fewer than 100 characters, removed odd characters, and only allowed lowercase characters.\n",
        "\n",
        "You’ll loop over the corpus file and generate the training pairs (technically 3-tuples: input text, target text with start token, and target text). While reading the corpus, you’ll also generate a set of input and target characters, which you’ll then use to onehot encode the samples. The input and target characters don’t have to match. \n",
        "\n",
        "But characters that aren’t included in the sets can’t be read or generated during the generation phase. The result of the following listing is two lists of input and target texts (strings), as well as two sets of characters that have been seen in the training corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcQZY0LL5tg0"
      },
      "source": [
        "# The arrays hold the input and target text read from the corpus file.\n",
        "input_texts, target_texts = [], []\n",
        "\n",
        "# The sets hold the seen characters in the input and target text.\n",
        "input_vocabulary = set()\n",
        "output_vocabulary = set()\n",
        "\n",
        "\"\"\"\n",
        "The target sequence is annotated with a start (first) and stop (last) token; the characters representing the tokens are\n",
        "defined here. These tokens can’t be part of the normal sequence text and should be uniquely used as start and stop tokens.\n",
        "\"\"\"\n",
        "start_token = \"\\t\"\n",
        "stop_token = \"\\n\"\n",
        "\n",
        "\"\"\"\n",
        "max_training_samples defines how many lines are used for the training. It’s the lower number\n",
        "of either a user-defined maximum or the total number of lines loaded from the file.\n",
        "\"\"\"\n",
        "max_training_samples = min(25000, len(df) - 1)\n",
        "\n",
        "for input_text, target_text in zip(df.statement, df.reply):\n",
        "  # The target_text needs to be wrapped with the start and stop tokens.\n",
        "  target_text = start_token + target_text + stop_token\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "\n",
        "  # Compile the vocabulary— set of the unique characters seen in the input_texts.\n",
        "  for char in input_text:\n",
        "    if char not in input_vocabulary:\n",
        "      input_vocabulary.add(char)\n",
        "  for char in target_text:\n",
        "    if char not in output_vocabulary:\n",
        "      output_vocabulary.add(char)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoaQcodmD0jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f6c489-6b35-44fb-ebce-1307cdbd14b4"
      },
      "source": [
        "input_texts[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"you're asking me out. that's so cute. what's your name again?\",\n",
              " \"no, no, it's my fault we didn't have a proper introduction \",\n",
              " 'gosh, if only we could find kat a boyfriend...',\n",
              " \"c'esc ma tete. this is my head\",\n",
              " 'how is our little find the wench a date plan progressing?']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a56bz-y3D5Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656d69c4-3c5f-42e6-cc93-21fc68a134e5"
      },
      "source": [
        "target_texts[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\tforget it.\\n',\n",
              " '\\tcameron.\\n',\n",
              " '\\tlet me see what i can do.\\n',\n",
              " \"\\tright. see? you're ready for the quiz.\\n\",\n",
              " \"\\twell, there's someone i think might be \\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un6VpScVD-XS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb1435b-1bbf-453a-b22b-f4b409de9f28"
      },
      "source": [
        "list(input_vocabulary)[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['g', 'c', 'm', '5', 'l', 'x', '.', \"'\", 'n', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR5y81pXEDZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75fbcbf-0e17-4c20-f31f-1593b38dcb7c"
      },
      "source": [
        "list(output_vocabulary)[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['g', 'c', 'm', '5', 'l', 'x', '.', \"'\", 'n', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTTH9JyuFSF8"
      },
      "source": [
        "##Building your character dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oY-v2zWD3_8"
      },
      "source": [
        "You need to convert each character of the input and target texts into one-hot vectors that represent each character. In order to generate the one-hot vectors, you generate token dictionaries (for the input and target text), where every character is mapped to an index. You also generate the reverse dictionary (index to character), which you’ll use during the generation phase to convert the generated index to a character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_94Er5VETIP"
      },
      "source": [
        "# You convert the character sets into sorted lists of characters, which you then use to generate the dictionary.\n",
        "input_vocabulary = sorted(input_vocabulary)\n",
        "output_vocabulary = sorted(output_vocabulary)\n",
        "\n",
        "# For the input and target data, you determine the maximum number of unique characters, which you use to build the one-hot matrices.\n",
        "input_vocab_size = len(input_vocabulary)\n",
        "output_vocab_size = len(output_vocabulary)\n",
        "\n",
        "# For the input and target data, you also determine the maximum number of sequence tokens.\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "# Loop over the input_characters and output_vocabulary to create the lookup dictionaries, which you use to generate the one-hot vectors.\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_vocabulary)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(output_vocabulary)])\n",
        "\n",
        "# Loop over the newly created dictionaries to create the reverse lookups.\n",
        "reverse_input_char_index = dict([(i, char) for char, i in input_token_index.items()])\n",
        "reverse_target_char_index = dict([(i, char) for char, i in target_token_index.items()])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQEzUEviGzdL",
        "outputId": "0001c10c-d8c1-481c-b5bd-09e6dad1ced7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(input_token_index)[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', '!', \"'\", ',', '.', '0', '1', '2', '3', '4']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMtlF8KuOoPT",
        "outputId": "bf04e1a8-a921-4494-c790-648721c9c0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(target_token_index)[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\t', '\\n', ' ', '!', \"'\", ',', '.', '0', '1', '2']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOrfAq7UOwch"
      },
      "source": [
        "## Generate one-hot encoded training sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFnw-2WtOxPZ"
      },
      "source": [
        ""
      ]
    }
  ]
}